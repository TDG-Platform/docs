# Supercube GBDX Workflow 

This document introduces the Supercube GBDX Workflow and describes how to modify it in order to generate a 16-band aligned AComp supercube from WV3 8-band DN VNIR and 8-band DN SWIR data. This workflow does not perform ortho-processing. The resulting supercube is at the VNIR pixel resolution, and its extent is that of the overlap of the VNIR and SWIR. The "mi_setup" task within this workflow requires that cloud and water processing be performed. Therefore cloud and water masks are output by this workflow, both at the VNIR resolution and cut to the extent of the supercube. For convenience, an RGB with the extent of the VNIR is also output. 

The outputs generated by this workflow (supercube, cloud mask, and water mask) can be fed directly into a DGLayers workflow. 

**_Supercube Workflow:_** 

```shell
import os
from gbdxtools import Interface
gbdx = Interface()

# NOTE: Make sure these directory strings have the trailing "/" as shown
in_base_dir = "s3://xxxxxxxxxxxxx/"
out_base_dir = "s3://xxxxxxxxxxxxx/"

####### INPUTS #######
dn_dir = os.path.join(in_base_dir, "dn_dir/")
vnir_dn_dir = os.path.join(dn_dir, "vnir/")
swir_dn_dir = os.path.join(dn_dir, "swir/")

####### OUTPUTS #######
out_rgb_dir = os.path.join(out_base_dir, "ACOMP_RGB")
out_scube_dir = os.path.join(out_base_dir, "ACOMP_SCUBE")
out_water_scube_dir = os.path.join(out_base_dir, "WATER_SCUBE")
out_cloud_scube_dir = os.path.join(out_base_dir, "CLOUD_SCUBE")
out_mi_mask_dir = os.path.join(out_base_dir, "MI_MASK")
out_mi_tmp_dir = os.path.join(out_base_dir, "MI_TMP")

####################################################################################

############# ACOMP - now assembles Acomp VNIR tiles into single TIF
acomp_task = gbdx.Task("AComp_internal",
                       data = dn_dir,
                       compute_noise = True)

acomp_dir = acomp_task.outputs.data.value

############# Copy VNIR to its own directory
cmd = "cp $indir/*-M*_ACOMP.TIF $outdir"
copy_task = gbdx.Task("gdal-cli",
                      command = cmd,
                      data = acomp_dir,
                      execution_strategy = 'runonce')

acomp_vnir_dir = copy_task.outputs.data.value

############# RGB 
cmd22 = "infile=`ls $indir/*.TIF`; "              # Note: back-ticks not single quotes
cmd22 += 'infname=$(basename "$infile" .TIF); '   
cmd22 += "outfname=$infname'_5_3_2_rgb.tif'; "       
cmd22 += "gdal_translate -b 5 -b 3 -b 2 $indir/*.TIF $outdir/$outfname"
rgb_task = gbdx.Task("gdal-cli",
                        command = cmd22,
                        data = acomp_vnir_dir,
                        execution_strategy = 'runonce')

rgb_dir = rgb_task.outputs.data.value 

save_rgb_task = gbdx.Task("StageDataToS3",
                            data = rgb_dir,
                            destination = out_rgb_dir)

############# Water Mask
# Build a water mask boolean raster. water = 255; non-water = 0
water_task = gbdx.Task("protogenV2RAW",
                       raster = acomp_vnir_dir)

water_vnir_dir = water_task.outputs.data.value

############# Cloud Mask
# Build a cloud mask boolean raster. cloud = 255; non-cloud = 0
cloud_task = gbdx.Task("protogenV2RAC",
                       raster = acomp_vnir_dir)

cloud_vnir_dir = cloud_task.outputs.data.value

############# Union Cloud and Water Mask for MI
# NOTE: The output mask file needs a very specific naming convention in order 
# to be ingested by mi_setup task. Here is example of output file name:
# 14AUG28191207-M2AS-054759622010_01_P001_ACOMP_LULC_MASK.tif
cmd33 = "infile=`ls $indir/dataC/*.tif`; "  # Note: back-ticks not single quotes
cmd33 += 'infname=$(basename "$infile" .tif); '  
cmd33 += "infprefix=${infname::39}; "
cmd33 += "outfname=$infprefix'_ACOMP_LULC_MASK.tif'; "
cmd33 += "mkdir $outdir/data; "
cmd33 += 'gdal_calc.py -A $indir/dataW/*.tif -B $indir/dataC/*.tif --outfile=$outdir/data/$outfname '
cmd33 += '--calc="numpy.where(B,B,A)" --type=Byte'
union_task = gbdx.Task('gdal-cli-multiplex')
union_task.inputs.dataC = cloud_vnir_dir
union_task.inputs.dataW = water_vnir_dir
union_task.inputs.command = cmd33
union_task.execution_strategy='runonce'

mi_mask_dir = union_task.outputs.data.value

save_mi_mask_task = gbdx.Task("StageDataToS3",
                            data = mi_mask_dir,
                            destination = out_mi_mask_dir)

############# Mutual Information v10
mi_task = gbdx.Task("mi_setup", 
                       vnirPort = vnir_dn_dir,
                       swirPort = swir_dn_dir,
                       acompPort = acomp_dir,
                       classPort = mi_mask_dir,
                       resamplingKernel = 'nearestNeighbour',  # <--This option does a bulk SWIR shift (other options: 'bilinear', 'bicubic')
                       useAComp = True, 
                       lulcMask = True,
                       waterMask = False,
                       cloudMask = False,
                       darkMask = True,
                       buildVrt = True,
                       buildAComp = False,
                       buildClassifier = False,
                       buildMask = True,
                       buildAlignImages = True)

# Wierd Gregory arguments 
dockerRoot = "/mnt/work/"
mi_task.inputs.vnirDir = os.path.join(dockerRoot, "input/vnirPort")
mi_task.inputs.swirDir = os.path.join(dockerRoot, "input/swirPort")
mi_task.inputs.acompDir = os.path.join(dockerRoot, "input/acompPort")
mi_task.inputs.classDir = os.path.join(dockerRoot, "input/classPort")
mi_task.inputs.outDir = os.path.join(dockerRoot, "output/outPort")
mi_task.inputs.tmpDir = os.path.join(dockerRoot, "output/tmpPort")
mi_task.inputs.statusFile = os.path.join(dockerRoot, "status.json")

# Name EC2 directories
mi_out_dir = mi_task.outputs.outPort.value
mi_tmp_dir = mi_task.outputs.tmpPort.value

save_mi_tmp_task = gbdx.Task("StageDataToS3",
                            data = mi_tmp_dir,
                            destination = out_mi_tmp_dir)

############# Stack MI SWIR on MI VNIR 
cmd44 = "infile=`ls $indir/*-A*.TIF`; "  # Note: back-ticks not single quotes
cmd44 += 'infname=$(basename "$infile" .TIF); '  
cmd44 += "infprefix=${infname::39}; "
cmd44 += "outfname=$infprefix'_ACOMP_SCUBE.TIF'; "
cmd44 += "gdal_merge.py -separate -o $outdir/$outfname $indir/*-M*.TIF $indir/*-A*.TIF"
stack_task = gbdx.Task("gdal-cli",
                      command = cmd44,
                      data = mi_out_dir,
                      execution_strategy = 'runonce')

scube_dir = stack_task.outputs.data.value

save_scube_task = gbdx.Task("StageDataToS3",
                            data = scube_dir,
                            destination = out_scube_dir)

# ########### Resample Water Mask to Supercube and cut to the overlap.
rc_water_scube_task = gbdx.Task("resample_and_cut_001",
                    input_A = water_vnir_dir,
                    input_B = scube_dir,
                    nodata_A='-1',
                    r_meth='near',
                    prefixLen='39',
                    osuffA='ACOMP_WATER_MASK')

water_scube_dir = rc_water_scube_task.outputs.out_A.value

save_water_scube_task = gbdx.Task("StageDataToS3",
                            data = water_scube_dir,
                            destination = out_water_scube_dir)

########### Resample Cloud Mask to Supercube and cut to the overlap.
rc_cloud_scube_task = gbdx.Task("resample_and_cut_001",
                    input_A = cloud_vnir_dir,
                    input_B = scube_dir,
                    nodata_A='-1',
                    r_meth='near',
                    prefixLen='39',
                    osuffA='ACOMP_CLOUD_MASK')

cloud_scube_dir = rc_cloud_scube_task.outputs.out_A.value

save_cloud_scube_task = gbdx.Task("StageDataToS3",
                            data = cloud_scube_dir,
                            destination = out_cloud_scube_dir)

##########################################################
workflow = gbdx.Workflow([acomp_task,
						  copy_task,
                          water_task,
                          cloud_task,
                          union_task,
                          save_mi_mask_task,
                          mi_task,
                          save_mi_tmp_task,
                          stack_task,
                          save_scube_task,
                          rc_water_scube_task,
                          save_water_scube_task,
                          rc_cloud_scube_task,
                          save_cloud_scube_task])


#print workflow.generate_workflow_description()
workflow.execute()
print
print workflow.id
```

The only modifications you need to make to this template are the following:
 
* Set **_in_base_dir_** -- this is the top-level S3 input directory that contains your DN data 
* Set **_out_base_dir_** -- this is the top-level S3 output directory
* Set **_dn_dir_**, **_vnir_dn_dir_**, and **_swir_dn_dir_** -- these are the S3 locations of the input DN data 
















